{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# any way to make this always run?\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# make sure we're in the right directory\n",
    "os.chdir('/Users/ryan-saloma/Python Projects/football_financials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_parsed_page(url):\n",
    "    # get the page\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def get_team_name(soup):\n",
    "    # get the team name\n",
    "    h1 = soup.find('h1').text\n",
    "    team_name = re.sub(r' \\d{4} Cap Table', '', h1)\n",
    "    return team_name\n",
    "\n",
    "# define the function to get the tables\n",
    "def get_tables(soup):\n",
    "    # get all the tables\n",
    "    tables = soup.find_all('table')\n",
    "    return tables\n",
    "\n",
    "# get the h2s of the page\n",
    "def get_h2s(soup):\n",
    "    h2s = soup.find_all('h2')\n",
    "    # extract text and remove leading/trailing whitespace\n",
    "    h2_list = [h2.text.strip() for h2 in h2s]\n",
    "    # keep only the h2s that start with year\n",
    "    h2_list = [h2 for h2 in h2_list if re.match(r'\\d{4}', h2)]\n",
    "    return h2_list\n",
    "\n",
    "# save the tables to a list with the team name\n",
    "def get_team_tables(url):\n",
    "    wait_time = np.random.randint(1, 5)\n",
    "    time.sleep(wait_time)\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    team_name = get_team_name(soup)\n",
    "    table_list = pd.read_html(page.content)\n",
    "    tables = []\n",
    "    for table in table_list:\n",
    "        tables.append(pd.DataFrame(table))\n",
    "    h2s = get_h2s(soup)\n",
    "    return team_name, tables, h2s\n",
    "\n",
    "# convert the h2 into string suitable for file name\n",
    "# make everything lowercase and replace spaces with underscores\n",
    "# replace / with and\n",
    "# remove any extra underscores\n",
    "def h2_to_str(h2):\n",
    "    h2 = h2.lower()\n",
    "    h2 = re.sub(r' ', '_', h2)\n",
    "    h2 = re.sub(r'/', '+', h2)\n",
    "    h2 = re.sub(r'_+', '_', h2)\n",
    "    return h2\n",
    "\n",
    "# get the team name\n",
    "def get_team_name(soup):\n",
    "    # get the team name\n",
    "    h1 = soup.find('h1').text\n",
    "    team_name = re.sub(r' \\d{4} Cap Table', '', h1)\n",
    "    return team_name\n",
    "\n",
    "# get the available years for each team\n",
    "def get_available_years(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    team_name = get_team_name(soup)\n",
    "    # format: <select name=\"year\" class=\"form-select form-select-sm\" tabindex=\"0\" control-id=\"ControlID-15\">\n",
    "    select = soup.find('select', {'name': 'year'})\n",
    "    options = select.find_all('option')\n",
    "    years = [option.text for option in options]\n",
    "    return team_name, years\n",
    "\n",
    "# handle changed team names\n",
    "def handle_team_name_changes(team_name):\n",
    "    match team_name:\n",
    "        case 'Oakland Raiders':\n",
    "            return 'Las Vegas Raiders'\n",
    "        case 'San Diego Chargers':\n",
    "            return 'Los Angeles Chargers'\n",
    "        case 'St. Louis Rams':\n",
    "            return 'Los Angeles Rams'\n",
    "        case 'Washington Football Team':\n",
    "            return 'Washington Commanders'\n",
    "        case 'Washington Redskins':\n",
    "            return 'Washington Commanders'\n",
    "        case _:\n",
    "            return team_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the team urls\n",
    "df = pd.read_csv(os.getcwd() + '/data/cap_space_all_teams.csv')\n",
    "team_urls = df['team_url']\n",
    "\n",
    "# get 2024 cap data for every team\n",
    "team_codes = pd.read_csv(os.getcwd() + '/data/team_codes.csv')\n",
    "team_codes = team_codes.set_index('team_name')\n",
    "team_codes = team_codes.to_dict()['team_code']\n",
    "for url in team_urls:\n",
    "    team_name, tables, headers = get_team_tables(url)\n",
    "    table_names = [h2_to_str(h2) for h2 in headers]\n",
    "    print(team_name)\n",
    "    os.mkdir(os.getcwd() + '/data/teams/' + team_name)\n",
    "    for i, table in enumerate(tables):\n",
    "        table.to_csv(os.getcwd() + '/data/teams/' + team_name + '/' + team_codes[team_name] + '_' + table_names[i] + '_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below should go in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the tables\n",
    "# change the column names to lowercase and replace spaces with underscores\n",
    "# replace player_(\\d+) with player\n",
    "# remove empty columns\n",
    "# remove empty rows\n",
    "# replace - with NaN\n",
    "# remove dollar signs and commas from columns that should be numeric\n",
    "# convert columns to numeric\n",
    "# remove extra underscores from column names\n",
    "# IMPORTANT: some of these steps are dependent on the previous cleaning steps (h2_to_str)\n",
    "\n",
    "def is_string_dtype(dtype):\n",
    "    return pd.api.types.is_string_dtype(dtype)\n",
    "\n",
    "# Function to find columns with dollar sign values\n",
    "def columns_with_dollar_or_percent(df):\n",
    "    # List to store columns with dollar or percent signs\n",
    "    cols_with_symbols = []\n",
    "    \n",
    "    # Iterate over columns\n",
    "    for col in df.columns:\n",
    "        # Check if any value in the column contains a dollar sign or percent sign\n",
    "        if df[col].astype(str).str.contains(r'\\$|%').any():\n",
    "            cols_with_symbols.append(col)\n",
    "    \n",
    "    return cols_with_symbols\n",
    "\n",
    "def clean_table(df):\n",
    "\n",
    "    # remove columns with names that contain 'Unnamed'\n",
    "    df = df.loc[:, ~df.columns.str.contains('Unnamed')]\n",
    "    \n",
    "    # substitute player_(\\d+) or Player_(\\d+) with player\n",
    "    # 11/1/24: added string type check to avoid error\n",
    "    # 11/1/24 2: replaced string type check with filter for Unnamed columns\n",
    "    df.columns = [re.sub(r'Player \\(\\d+\\)|player \\(\\d+\\)', 'player', col) for col in df.columns]\n",
    "    df.columns = [col.lower().replace(' ', '_') for col in df.columns]\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df = df.dropna(axis=0, how='all')\n",
    "    df = df.replace('-', '')\n",
    "    df.columns = [re.sub(r'_+', '_', col) for col in df.columns]\n",
    "    # Add player column if it doesn't exist\n",
    "    # Move this to the beginning of the function\n",
    "    if ('player' not in df.columns):\n",
    "        df.insert(0, 'player', np.nan)\n",
    "\n",
    "    # Remove first instance of duplicate string group in player column\n",
    "    # Example: 'Carter Michael Carter' -> 'Michael Carter'\n",
    "    reformatted_column = []\n",
    "    for player in df['player']:\n",
    "        if type(player) == str:\n",
    "            reformatted_column.append(re.sub(r'^(.*?)\\s+(.*?)\\s+(\\1)', r'\\2 \\1', player))\n",
    "        else:\n",
    "            reformatted_column.append(player)\n",
    "    # reformatted_column = [re.sub(r'^(.*?)\\s+(.*?)\\s+(\\1)', r'\\2 \\1', player) for player in df['player']]\n",
    "    df['player'] = reformatted_column\n",
    "\n",
    "    # check that column is string before using str.contains\n",
    "    # get columns with dollar signs and commas\n",
    "    cols = columns_with_dollar_or_percent(df)\n",
    "    for col in cols:\n",
    "        df[col] = df[col].str.replace('$', '')\n",
    "        df[col] = df[col].str.replace('%', '')\n",
    "        df[col] = df[col].str.replace(',', '')\n",
    "        df[col] = df[col].str.replace('(', '-')\n",
    "        df[col] = df[col].str.replace(')', '')\n",
    "        df[col] = pd.to_numeric(df[col])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies: is_string_dtype, columns_with_dollar_or_percent, clean_table\n",
    "\n",
    "# clean the tables for 2024\n",
    "for team_name in team_codes.keys():\n",
    "    team_code = team_codes[team_name]\n",
    "    team_path = os.getcwd() + '/data/teams/' + team_name\n",
    "    files = os.listdir(team_path)\n",
    "    files = [file for file in files if file.endswith('.csv') and 'all_players' not in file and 'cap_totals' not in file]\n",
    "    all_players = pd.DataFrame()\n",
    "    for file in files:\n",
    "        df = pd.read_csv(team_path + '/' + file)\n",
    "        df = clean_table(df)  \n",
    "        all_players = pd.concat([all_players, df])\n",
    "    all_players.to_csv(team_path + '/' + team_code + '2024_all_players_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies: get_team_name, get_available_years\n",
    "\n",
    "# get all of the available years for each team\n",
    "df = pd.read_csv(os.getcwd() + '/data/cap_space_all_teams.csv')\n",
    "team_urls = df['team_url']\n",
    "team_years = pd.DataFrame(columns=['team_name', 'year'])\n",
    "for url in team_urls:\n",
    "    team_name, years = get_available_years(url)\n",
    "    for year in years:\n",
    "        team_years = pd.concat([team_years, pd.DataFrame({'team_name': team_name, 'year': year}, index=[0])])\n",
    "team_years.to_csv(os.getcwd() + '/data/team_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_years = pd.read_csv(os.getcwd() + '/data/team_years.csv')\n",
    "team_urls = pd.read_csv(os.getcwd() + '/data/cap_space_all_teams.csv')\n",
    "team_codes = pd.read_csv(os.getcwd() + '/data/team_codes.csv')\n",
    "team_codes = team_codes.set_index('team_name')\n",
    "team_codes = team_codes.to_dict()['team_code']\n",
    "\n",
    "# for url in team_urls['team_url']:\n",
    "for url in team_urls['team_url']:\n",
    "    # get the year from url\n",
    "    year = re.search(r'(\\d{4})', url).group(1)\n",
    "    year = int(year)\n",
    "\n",
    "    # go through each year and get page until 2011\n",
    "    while year > 2011:\n",
    "\n",
    "        page = requests.get(new_url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        team_name = get_team_name(soup)\n",
    "        team_name = handle_team_name_changes(team_name)\n",
    "\n",
    "        # get tables as list of dataframes\n",
    "        table_list = pd.read_html(page.content)\n",
    "        tables = []\n",
    "        for table in table_list:\n",
    "            tables.append(pd.DataFrame(table))\n",
    "\n",
    "        # get h2s of the page for table names\n",
    "        h2s = get_h2s(soup)\n",
    "        table_names = [h2_to_str(h2) for h2 in h2s]\n",
    "\n",
    "        dir = os.getcwd() + '/data/teams/' + team_name + '/' + str(year)\n",
    "        # check if directory exists\n",
    "        if not os.path.exists(dir):\n",
    "            os.mkdir(dir) # assumes that directory does not exist\n",
    "\n",
    "        for i, table in enumerate(tables):\n",
    "            file = dir + '/' + team_codes[team_name] + '_' + table_names[i] + '_raw.csv'\n",
    "            # check if file exists\n",
    "            if os.path.exists(file):\n",
    "                continue\n",
    "            # check if the format is normal or cap_totals\n",
    "            if 'cap_totals' not in table_names[i]:\n",
    "                cleaned_table = clean_table(table)\n",
    "            else:\n",
    "                table.columns = table.iloc[0]\n",
    "                cleaned_table = table.iloc[1:]\n",
    "\n",
    "            cleaned_table.to_csv(file, index=False)\n",
    "        year = year - 1\n",
    "        new_url = re.sub(r'\\d{4}', str(year), url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all tables that aren't 'cap_totals' into one table for each team and year\n",
    "for team_name in team_codes.keys():\n",
    "    team_code = team_codes[team_name]\n",
    "    team_path = os.getcwd() + '/data/teams/' + team_name\n",
    "    years = [year for year in os.listdir(team_path) if os.path.isdir(team_path + '/' + year)]\n",
    "    for year in years:\n",
    "        files = os.listdir(team_path + '/' + year)\n",
    "        files = [file for file in files if file.endswith('_cleaned.csv') and 'cap_totals' not in file]\n",
    "        # print(f'{team_name}: {files}')\n",
    "        all_players = pd.DataFrame()\n",
    "        for file in files:\n",
    "            df = pd.read_csv(team_path + '/' + year + '/' + file)\n",
    "            # check that none of df columns contain 'Cap Maximum Summary'\n",
    "            if df.columns.str.contains('Cap Maximum Summary').any():\n",
    "                print(f'{file} contains Cap Maximum Summary')\n",
    "                df = df.loc[:, ~df.str.contains('Cap Maximum Summary')]\n",
    "                df = df.dropna(axis=1, how='all')\n",
    "            all_players = pd.concat([all_players, df])\n",
    "        all_players.to_csv(team_path + '/' + year + '/' + team_code + '_' + year + '_all_players_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine every all_players table into one table for each team with column for year\n",
    "for team_name in team_codes.keys():\n",
    "    team_code = team_codes[team_name]\n",
    "    team_path = os.getcwd() + '/data/teams/' + team_name\n",
    "    years = [year for year in os.listdir(team_path) if os.path.isdir(team_path + '/' + year)]\n",
    "    all_players = pd.DataFrame()\n",
    "    for year in years:\n",
    "        df = pd.read_csv(team_path + '/' + year + '/' + team_code + '_' + year + '_all_players_cleaned.csv')\n",
    "        df['team_name'] = team_name\n",
    "        df['year'] = year\n",
    "        df = df[['team_name', 'year'] + [col for col in df.columns if col not in ['team_name', 'year']]]\n",
    "        all_players = pd.concat([all_players, df])\n",
    "    all_players.to_csv(team_path + '/' + team_code + '_all_players_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all of all_players_cleaned tables into one table\n",
    "all_players = pd.DataFrame()\n",
    "for team_name in team_codes.keys():\n",
    "    team_code = team_codes[team_name]\n",
    "    team_path = os.getcwd() + '/data/teams/' + team_name\n",
    "    files = os.listdir(team_path)\n",
    "    files = [file for file in files if file.endswith('_all_players_cleaned.csv')]\n",
    "    if len(files) == 0:\n",
    "        print(f'{team_name} has no all_players_cleaned.csv')\n",
    "        continue\n",
    "    elif len(files) > 1:\n",
    "        print(f'{team_name} has more than one all_players_cleaned.csv')\n",
    "        continue\n",
    "    df = pd.read_csv(team_path + '/' + files[0])\n",
    "    all_players = pd.concat([all_players, df])\n",
    "\n",
    "all_players.to_csv(os.getcwd() + '/data/' + 'all_players_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
